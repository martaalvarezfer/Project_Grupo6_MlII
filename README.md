# **Machine Learning II ‚Äì Deep Learning Project**

## **Canonist.ia**

El objetivo de este proyecto es aplicar *transfer learning* a un caso de negocio simulado relacionado con portales inmobiliarios y desplegar el modelo en una aplicaci√≥n **Streamlit** accesible p√∫blicamente.

La aplicaci√≥n recibe una imagen y la clasifica seg√∫n su entorno (**habitaci√≥n**, **cocina**, **bosque**, **industria**, etc.), utilizando diversas **CNN preentrenadas** que se ajustan a nuestras necesidades. Para ello, se entrenan varios modelos empleando la plataforma **Weights & Biases (W&B)**, donde se reportan m√©tricas detalladas y se comparan entre ellos. 

Una vez entrenado el modelo, se integra en una app **Streamlit** que permite a los usuarios cargar im√°genes y obtener una predicci√≥n de forma sencilla y en tiempo real.

Este proyecto se ha desarrollado como parte de la asignatura *Machine Learning II* del **M√°ster en Big Data** de la Universidad **Comillas ICAI**.

### üë• **Equipo del proyecto**

| Nombre                      | Email                              |
|----------------------------|------------------------------------|
| Marta √Ålvarez Fern√°ndez    | 202402675@alu.comillas.edu         |
| Leticia C√≥lgan Valero      | leticiacologan@alu.comillas.edu    |
| Ana Vera Pe√±a              | 202416868@alu.comillas.edu         |
| Antonio Bajo G√≥mez-Madurga | 202410510@alu.comillas.edu         |

---

## ‚öôÔ∏è **Requisitos previos**

1. Clona el repositorio

```bash
git clone https://github.com/martaalvarezfer/Project_Grupo6_MLII.git
```

2. Crea el entorno virtual e instala las dependencias

```bash
cd Project_Grupo6_MLII
python -m venv venv
source venv/bin/activate
pip install --upgrade pip
pip install -r requirements.txt
```

3. Aseg√∫rate de incluir en `.gitignore` tus archivos sensibles y los `.pt`.

---

## üìÅ **Estructura de carpetas**

- `src/`  
  - `project/`: scripts de entrenamiento, arquitectura CNN, comparaciones y generaci√≥n de CSVs de predicci√≥n.  
  - `streamlit/`: script para lanzar la app.
- `models/`: contiene los archivos `.pt` con los pesos entrenados (NO incluidos en GitHub).
- `dataset/`: conjunto de im√°genes utilizadas para entrenamiento y validaci√≥n.
- `img/`: im√°genes ilustrativas como capturas de la app.

‚ö†Ô∏è **Importante**  
Los archivos `.pt` superan los **100‚ÄØMB**, por lo tanto no se incluyen en GitHub. Adem√°s, tampoco pudimos alojarlos correctamente en W&B.  
Para usar la app, debes descargarlos desde esta carpeta de Google Drive y colocarlos en el directorio `models/`:

üîó https://drive.google.com/drive/folders/16Kv4ADU2d1ow-46PWrHoT4E0jnmw3cOn?usp=sharing

---

## üß† **Modelo seleccionado**

**ConvNeXt Base** entrenado con **Cross-Entropy Loss**

Este modelo ha sido el mejor evaluado. Se ha utilizado la arquitectura `convnext_base`, preentrenada en ImageNet, ajustada mediante *fine-tuning* descongelando las √∫ltimas **5 capas**. Entrenado durante **7 √©pocas**, con im√°genes RGB de tama√±o **224x224**, usando:

- Optimizador: `Adam`
- Learning rate: `0.0001`
- Funci√≥n de p√©rdida: `Cross-Entropy`

üìä **Resultados:**

- Entrenamiento: **91.06%**
- Validaci√≥n: **93.60%**
- Train loss: `0.275`
- Val loss: `0.178`

üîç **Errores m√°s comunes del modelo:**

El modelo tiene dificultades para diferenciar entornos visualmente similares, por ejemplo:

- `Bedroom` ‚Üí `Living room` 
- `Office` ‚Üí `Kitchen` 

Esto sugiere que las confusiones se dan principalmente en interiores con elementos comunes como iluminaci√≥n o distribuci√≥n.

---

## üöÄ **Lanzar la app**

Puedes probar el modelo directamente con la app ejecutando:

```bash
streamlit run src/streamlit/app.py
```

### Ejemplo de interfaz:

![App](img/app.png)

---

## üîß **Mejoras propuestas**

1. **Aumentar la variedad del dataset**  
   Aplicar t√©cnicas como *data augmentation* (rotaciones, escalado, etc.).

2. **Modelos de segundo nivel**  
   Hemos detectado que nuestros modelos son mejores en cierto tipo de imagen que en otras, es decir en algunas no presenta un porcentaje       alto de confianza en ninguna de ellas. Por tanto estas dudodas se pasar√≠an a submodelos que est√°n especializados en diversos tipos de       im√°genes y se seleccionaria el que presente el mayor porcentaje de confianza. Por tanto podr√≠amos aplicar un primer modelo que detecte.     Esta t√©cnica puede aumentar la precisi√≥n general, porque permite hacer predicciones m√°s cuidadosas y espec√≠ficas en los casos m√°s           dif√≠ciles, en lugar de forzar una decisi√≥n poco segura con el modelo principal.

3. **Entrenamiento con GPU**  
   Limitaci√≥n clave del proyecto. Modelos m√°s pesados como `resnext101_64x4d` no se han podido entrenar completamente.

4. **Descongelar capas espec√≠ficas**  
   En lugar de hacerlo por n√∫mero, elegir capas concretas relevantes.

5. **Funci√≥n de p√©rdida personalizada**  
   Adaptarla a desequilibrios o dificultades del dataset.

---

Este proyecto nos ha permitido simular un flujo real de desarrollo de un modelo en producci√≥n, incluyendo la monitorizaci√≥n, evaluaci√≥n, y despliegue en una aplicaci√≥n funcional para el usuario final.
